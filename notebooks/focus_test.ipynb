{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744c695a",
   "metadata": {},
   "source": [
    "# EEG Focus Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the process of retrieving EEG data and associated focus labels from Google Cloud Firestore, extracting and preparing the raw EEG signal from the RIGHT_TEMP channel (sampled at 256 Hz), and performing signal processing and feature extraction. The workflow includes:\n",
    "\n",
    "1. **Data Retrieval:** Fetching EEG and focus label data from Firestore.\n",
    "2. **Preprocessing:** Extracting the RIGHT_TEMP channel, aligning time, and organizing data into a DataFrame.\n",
    "3. **Signal Processing:** Filtering (bandpass and notch), detrending, and flattening the data for analysis.\n",
    "4. **Spectral Analysis:** Computing the power spectral density (PSD) for each segment.\n",
    "5. **Feature Extraction:** Calculating bandpower for standard EEG bands and computing focus and engagement indices.\n",
    "6. **Comparison:** Normalizing and comparing the computed indices to the ground-truth focus label for further study.\n",
    "\n",
    "Each code cell below is commented to clarify its purpose and the steps involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and initialize Firebase Admin SDK using credentials from environment variable\n",
    "import firebase_admin\n",
    "from google.cloud import firestore\n",
    "from firebase_admin import credentials\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Initialize Firebase app with the Google Application Credentials\n",
    "cred = credentials.Certificate(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
    "firebase_admin.initialize_app(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc13436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Firestore client\n",
    "firestore_client = firestore.Client()\n",
    "\n",
    "# Define the collection and document paths\n",
    "collection_ref = firestore_client.collection(\"eeg_data\")\n",
    "document_ref = collection_ref.document(\"cristiana.principato@gmail.com\")\n",
    "eeg_doc = document_ref.collection(\"live_data\")\n",
    "focus_doc = document_ref.collection(\"focus_sessions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom helper functions (assumed to contain utility code for this analysis)\n",
    "from awearfunction_pd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all EEG and focus label documents as lists of dictionaries\n",
    "eeg_data = [doc_snapshot.to_dict() for doc_snapshot in eeg_doc.stream()]\n",
    "focus_data = [doc_snapshot.to_dict() for doc_snapshot in focus_doc.stream()]\n",
    "\n",
    "# Print the first entry of each for inspection\n",
    "print(eeg_data[0])\n",
    "print(focus_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "# only waveform data from waveformRIGHT_TEMP at 256 Hz\n",
    "raw_data = []\n",
    "timestamps = []\n",
    "utc_timestamps = []\n",
    "for i in eeg_data:\n",
    "    if len(i[\"waveformRIGHT_TEMP\"]) == 256:\n",
    "        raw_data.append(i[\"waveformRIGHT_TEMP\"])\n",
    "        timestamps.append(i[\"timestamp\"])\n",
    "        dt = datetime.fromisoformat(str(i[\"timestamp\"])).replace(tzinfo=timezone.utc)\n",
    "        utc_timestamps.append(dt.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8710eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the number of samples per segment and total number of segments\n",
    "n_samples = 256\n",
    "n_segments = len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ea45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fs = 256  # Sampling rate in Hz\n",
    "\n",
    "# Convert lists to numpy arrays and prepare for DataFrame creation\n",
    "raw_data = np.array(raw_data)\n",
    "segments = np.repeat([f'seg_{i}' for i in range(n_segments)], n_samples)\n",
    "timestamps = np.repeat(timestamps, n_samples)\n",
    "utc_timestamps = np.repeat(utc_timestamps, n_samples)\n",
    "time_s = np.tile(np.arange(n_samples) / fs, n_segments)  # Time within each segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data and create a long-form DataFrame for analysis\n",
    "long_df = pd.DataFrame({\n",
    "    'sample_value': raw_data.flatten(),\n",
    "    'segment': segments,\n",
    "    'time_UTC': utc_timestamps,\n",
    "    'timestamp': timestamps,\n",
    "    'time_sample': time_s\n",
    "})\n",
    "\n",
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, iirnotch, detrend\n",
    "\n",
    "# Bandpass filter: retain frequencies between 1-47 Hz (typical EEG range)\n",
    "def bandpass_filter(x, fs, lowcut=1.0, highcut=47.0, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "# Notch filter: remove 60 Hz powerline noise\n",
    "def notch_filter(x, fs, freq=60.0, Q=30.0):\n",
    "    nyq = 0.5 * fs\n",
    "    w0 = freq / nyq\n",
    "    b, a = iirnotch(w0, Q)\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "# Full preprocessing pipeline for a segment: bandpass, notch, and detrend\n",
    "def preprocess_segment(x, fs):\n",
    "    x = bandpass_filter(x, fs)\n",
    "    x = notch_filter(x, fs)\n",
    "    x = detrend(x)\n",
    "    return x\n",
    "\n",
    "# Apply preprocessing to all segments\n",
    "filtered = np.array([preprocess_segment(seg, fs) for seg in raw_data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efe09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the filtered signal to the DataFrame for further analysis\n",
    "long_df['filtered_value'] = filtered.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290af0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "# Compute the power spectral density (PSD) for a segment using Welch's method\n",
    "def compute_psd(seg, fs):\n",
    "    freqs, psd = welch(seg, fs=fs, nperseg=len(seg), window='hann')\n",
    "    return freqs, psd\n",
    "\n",
    "# Example: compute PSD for the first segment\n",
    "freqs, psd = compute_psd(filtered[0], fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EEG frequency bands\n",
    "bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30),\n",
    "    'gamma': (30, 47),\n",
    "}\n",
    "\n",
    "# Compute bandpower for a given frequency band\n",
    "def bandpower(freqs, psd, band):\n",
    "    mask = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    return np.trapz(psd[mask], freqs[mask])\n",
    "\n",
    "# Extract features: bandpowers and indices\n",
    "def extract_band_features(freqs, psd):\n",
    "    powers = {name: bandpower(freqs, psd, b) for name, b in bands.items()}\n",
    "    powers['theta_beta_ratio'] = powers['theta'] / powers['beta'] if powers['beta'] > 0 else np.nan\n",
    "    powers['engagement_index'] = powers['alpha'] / powers['beta'] if powers['beta'] > 0 else np.nan\n",
    "    powers['focus_index'] = powers['beta'] / (powers['theta'] + powers['alpha']) if (powers['theta'] + powers['alpha']) > 0 else np.nan\n",
    "    return powers\n",
    "\n",
    "# Compute features for all segments and create a DataFrame\n",
    "features = [extract_band_features(*compute_psd(seg, fs)) for seg in filtered]\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "features_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fcac7",
   "metadata": {},
   "source": [
    "# Focus Index\n",
    "\n",
    "Focus Index = Beta Power / (Alpha Power + Theta Power)\n",
    "\n",
    "High = alert, concentrated\n",
    "Low = distracted, drowsy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9f0c7",
   "metadata": {},
   "source": [
    "# Engagement index\n",
    "Engagement Index = Alpha Power / Beta Power\n",
    "\n",
    "High = alert, concentrated\n",
    "Low = distracted, drowsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce45057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the focus and engagement indices (z-score) for comparison\n",
    "for col in ['focus_index', 'engagement_index']:\n",
    "    features_df[col+'_norm'] = (features_df[col] - features_df[col].mean()) / features_df[col].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ebda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Construct time vector\n",
    "segment_duration = 256 / 256  # 1.0s per segment if fs = 256\n",
    "features_df['time_s'] = features_df.index * segment_duration\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=features_df['time_s'],\n",
    "    y=features_df['focus_index'],\n",
    "    mode='lines+markers',\n",
    "    name='Focus Index',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=features_df['time_s'],\n",
    "    y=features_df['engagement_index'],\n",
    "    mode='lines+markers',\n",
    "    name='Engagement Index',\n",
    "    line=dict(color='orange')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='EEG-Derived Focus and Engagement Over Time',\n",
    "    xaxis_title='Time (s)',\n",
    "    yaxis_title='Index (z-scored)',\n",
    "    width=900,\n",
    "    height=400,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd51c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(features_df, x='engagement_index', nbins=1000, title='Histogram of Engagement Index')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1818ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.engagement_index.min(), features_df.engagement_index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430139ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
